{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f38bfac5-cd1e-4189-b504-18c6f6abc682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623e33b5-989c-4b6d-9ac3-2d59c8e7131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.sparse import hstack, vstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6c08f15-5b36-4537-ad26-587b5040bfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.68 s, sys: 170 ms, total: 1.85 s\n",
      "Wall time: 1.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "train = pd.read_csv('../input/train.csv.zip').fillna(' ')\n",
    "test = pd.read_csv('../input/test.csv.zip').fillna(' ')\n",
    "\n",
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "all_text = pd.concat([train_text, test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8251a920-4709-4a35-89d2-8863dd7c8971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.4 s, sys: 141 ms, total: 21.5 s\n",
      "Wall time: 21.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=10000)\n",
    "word_vectorizer.fit(all_text)\n",
    "train_word_features = word_vectorizer.transform(train_text)\n",
    "test_word_features = word_vectorizer.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7f83ad0-8597-44e0-a425-f7b6b23feb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:546: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 25s, sys: 7.04 s, total: 10min 32s\n",
      "Wall time: 10min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "char_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='char',\n",
    "    stop_words='english',\n",
    "    ngram_range=(2, 6),\n",
    "    max_features=50000)\n",
    "char_vectorizer.fit(all_text)\n",
    "train_char_features = char_vectorizer.transform(train_text)\n",
    "test_char_features = char_vectorizer.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d6d0c12-f202-49d5-9c17-e4232e77fe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = hstack([train_char_features, train_word_features])\n",
    "test_features = hstack([test_char_features, test_word_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a71e016f-fbcd-42f0-80b8-988a5d543d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class toxic is 0.9783285513093992\n",
      "CV score for class severe_toxic is 0.9885276555375122\n",
      "CV score for class obscene is 0.990128534885006\n",
      "CV score for class threat is 0.989654551343866\n",
      "CV score for class insult is 0.982625117960518\n",
      "CV score for class identity_hate is 0.9823768625964755\n",
      "Total CV score is 0.9852735456054629\n",
      "CPU times: user 10min 38s, sys: 4.13 s, total: 10min 43s\n",
      "Wall time: 10min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = []\n",
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "for class_name in class_names:\n",
    "    train_target = train[class_name]\n",
    "    classifier = LogisticRegression(solver='sag')\n",
    "\n",
    "    cv_score = np.mean(cross_val_score(classifier, train_features, train_target, cv=3, scoring='roc_auc'))\n",
    "    scores.append(cv_score)\n",
    "    print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "\n",
    "    classifier.fit(train_features, train_target)\n",
    "    submission[class_name] = classifier.predict_proba(test_features)[:, 1]\n",
    "\n",
    "print('Total CV score is {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf4217ad-732f-4cc8-89a2-300eaee388df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[class_names].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "937c22be-ace9-4439-b441-ed2132468083",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oof = np.zeros(train[class_names].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da8edaf7-9b83-4876-981b-d1b417b9a15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[class_names].values[list(range(67)),0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99d186c7-f19b-40f3-a59d-d8f5f3e5dbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, random_state=137, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f822fef5-87d1-4888-89e8-c2ece9351567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting target 1\n",
      "Fitting fold 1\n",
      "Fitting fold 2\n",
      "Fitting fold 3\n",
      "Fitting target 2\n",
      "Fitting fold 1\n",
      "Fitting fold 2\n",
      "Fitting fold 3\n",
      "Fitting target 3\n",
      "Fitting fold 1\n",
      "Fitting fold 2\n",
      "Fitting fold 3\n",
      "Fitting target 4\n",
      "Fitting fold 1\n",
      "Fitting fold 2\n",
      "Fitting fold 3\n",
      "Fitting target 5\n",
      "Fitting fold 1\n",
      "Fitting fold 2\n",
      "Fitting fold 3\n",
      "Fitting target 6\n",
      "Fitting fold 1\n",
      "Fitting fold 2\n",
      "Fitting fold 3\n",
      "CPU times: user 6min 36s, sys: 4.07 s, total: 6min 40s\n",
      "Wall time: 6min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kf = KFold(n_splits=3, random_state=137, shuffle=True)\n",
    "for ii in range(6):\n",
    "    print(\"Fitting target\", ii+1)\n",
    "    for jj, (train_index, val_index) in enumerate(kf.split(train_features)):\n",
    "        print(\"Fitting fold\", jj+1)\n",
    "        train_x = train_features[train_index]\n",
    "        val_x = train_features[val_index]\n",
    "        train_target = train[class_names].values[train_index,ii]\n",
    "        classifier = LogisticRegression(solver='sag')\n",
    "        classifier.fit(train_x, train_target)\n",
    "        train_oof[val_index, ii] = classifier.predict_proba(val_x)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6cea721c-4d9f-43db-a3ae-4f90f8bdfe28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9784132615908256\n",
      "0.9881219309055794\n",
      "0.9902337988079097\n",
      "0.9898252126259562\n",
      "0.9823175830650794\n",
      "0.9827057819292789\n"
     ]
    }
   ],
   "source": [
    "for ii in range(6):\n",
    "    print(roc_auc_score(train[class_names].values[:,ii], train_oof[:,ii]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f820f96b-65ed-4d07-8c48-5781c0527128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting target 1\n",
      "Fitting fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.8/site-packages/daal4py/sklearn/linear_model/logistic_path.py:548: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting fold 2\n",
      "Fitting fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.8/site-packages/daal4py/sklearn/linear_model/logistic_path.py:548: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9784124598949604\n",
      "Fitting target 2\n",
      "Fitting fold 1\n",
      "Fitting fold 2\n",
      "Fitting fold 3\n",
      "0.9881218674063899\n",
      "Fitting target 3\n",
      "Fitting fold 1\n",
      "Fitting fold 2\n",
      "Fitting fold 3\n",
      "0.99023357481564\n",
      "Fitting target 4\n",
      "Fitting fold 1\n",
      "Fitting fold 2\n",
      "Fitting fold 3\n",
      "0.9898250153781003\n",
      "Fitting target 5\n",
      "Fitting fold 1\n",
      "Fitting fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.8/site-packages/daal4py/sklearn/linear_model/logistic_path.py:548: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting fold 3\n",
      "0.9823175713485555\n",
      "Fitting target 6\n",
      "Fitting fold 1\n",
      "Fitting fold 2\n",
      "Fitting fold 3\n",
      "0.9827052869315238\n",
      "CPU times: user 38min 22s, sys: 1h 31min 30s, total: 2h 9min 53s\n",
      "Wall time: 10min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for ii in range(6):\n",
    "    print(\"Fitting target\", ii+1)\n",
    "    for jj, (train_index, val_index) in enumerate(kf.split(train_features)):\n",
    "        print(\"Fitting fold\", jj+1)\n",
    "        train_x = train_features[train_index]\n",
    "        val_x = train_features[val_index]\n",
    "        train_target = train[class_names].values[train_index,ii]\n",
    "        classifier = LogisticRegression()\n",
    "        classifier.fit(train_x, train_target)\n",
    "        train_oof[val_index, ii] = classifier.predict_proba(val_x)[:,1]\n",
    "    print(roc_auc_score(train[class_names].values[:,ii], train_oof[:,ii]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c120f50-9797-450f-8c97-7af393c97529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
